{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUH91JWlJAQX"
   },
   "source": [
    "# Invoice reading NLP system\n",
    "Remember this image? IT IS BACK!!!\n",
    "![System image](https://storage.googleapis.com/aibootcamp/general_assets/ml_system_architecture.png)\n",
    "\n",
    "\n",
    "This week is all about system building. Because hardly ever does a ML system stand alone. Your success in building a system for Ortec Finance depends as much on what is around your neural net as it depends on the neural net itself. This baseline is my approach to the problem. Much in this notebook was hacked together so I am sure you can improve on many points. Perhaps you even come up with a completely different approach.\n",
    "\n",
    "## The approach, character wise classification:\n",
    "The goal of the task is to extract information from the invoice. The invoice has been run through optical character recognition (OCR). OCR turns PDFs into texts but often messes up the order and confuses come characters. **To extract information from this text, we classify each character by category**. \n",
    "\n",
    "Take an example, if we just wanted to get the amount we would classify the characters like this:\n",
    "\n",
    "|T|O|T|A|L|:| |€| |4|3|6|.|0|0|\n",
    "|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|\n",
    "|0|0|0|0|0|0|0|1|1|1|1|1|1|1|1|\n",
    "\n",
    "We classify our text into 6 classes here:\n",
    "\n",
    "Ignore:           0\n",
    "Sender Name:      1 \n",
    "Sender KVK:       2 \n",
    "Sender IBAN:      3 \n",
    "Invoice Reference:4\n",
    "Total:            5\n",
    "\n",
    "These are the classes that the training data generator tags. But the class of a character does not only depend on the character. It depends on its surroundings as well. To train our model, we create substrings of our invoice that include a certain amount of preceeding and succeeding characters. The amount of preceding and succeeding characters is defined in the `PADDING` global variable. \n",
    "\n",
    "If for example we wanted to classify the character '€' from the example above and had `PADDING = 3` we would feed\n",
    "'L: € 43' into our network. You can see how the amount of padding has a great influence on the performance of our system.\n",
    "\n",
    "## Post processing:\n",
    "A significant part of model performance stems from what is done with the outputs of the neural net. This approach groups predictions to prediction sequences and only keeps predictions in which 5 consecutive characters were grouped into the same category. An approach to try would be to allow sequences to be interrupted by one character. Another nice add on would be to rank predicted sequences by the total confidence the neural network has in the sequence. \n",
    "\n",
    "## Some tips:\n",
    "For this assignment you can dive pretty deep into software development. \n",
    "You might find these jupyter tricks helpful: https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/\n",
    "\n",
    "Especially debugging with `pdb` really makes things easier: https://docs.python.org/3.5/library/pdb.html#debugger-commands\n",
    "\n",
    "Basically, if anything crashes, you can start a new cell and enter `%debug`. You then come to a command line in which you can look around what happened at the crash.\n",
    "The debugger has some special commands. For example `p my_var` prints out a variable. This also works for other python operations, e.g. `p len(my_list)`.\n",
    "\n",
    "Good luck with building a great system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cat": "Other",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "colors": "BasicMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "cp": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "lf": "Other",
        "lk": "Other",
        "ll": "Other",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "lx": "Other",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "man": "KernelMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "mv": "Other",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "BasicMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "profile": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rm": "Other",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %popd  %pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%lsmagic\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1757,
     "status": "ok",
     "timestamp": 1521011534880,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "J_mZzOVTJT6D",
    "outputId": "6c4d4fd8-d58e-43fa-9b62-324b0f4f68ad"
   },
   "source": [
    "# Setup \n",
    "!wget https://storage.googleapis.com/aibootcamp/data/ortec_templates.zip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 323,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1254,
     "status": "ok",
     "timestamp": 1521011544747,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "qXnlL2boJjII",
    "outputId": "c7c53e1c-59c8-4daf-b435-74f9b4d57fa9"
   },
   "source": [
    "!unzip ortec_templates.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1270,
     "status": "ok",
     "timestamp": 1521013346934,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "_DnStomIJjRk",
    "outputId": "32faaed6-2562-4fbe-c88a-24e71f90d110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jannes_Baseline_Ortec.ipynb     Wk6_Ortec_IBAN_generation.ipynb\r\n",
      "LICENSE                         \u001b[34mtemplates\u001b[m\u001b[m\r\n",
      "README.md                       \u001b[34mtemplates-2\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vOyKxSEhdcy4"
   },
   "outputs": [],
   "source": [
    "# !cat templates/TEMPLATE_1.txt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "caddquRKJ2vC"
   },
   "source": [
    "!pip install -q keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3EuDqPXJAQZ"
   },
   "source": [
    "## Loading templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Mq9VfteLJAQZ"
   },
   "outputs": [],
   "source": [
    "# System hyper parameters here\n",
    "\n",
    "# How many characters before and after the main char to feed the NN\n",
    "PADDING = 20 \n",
    "\n",
    "\n",
    "'''\n",
    "Ignore:           0\n",
    "Sender Name:      1 \n",
    "Sender KVK:       2 \n",
    "Sender IBAN:      3 \n",
    "Invoice Reference:4\n",
    "Total:            5\n",
    "'''\n",
    "N_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "B5nyjD3ZJAQd"
   },
   "outputs": [],
   "source": [
    "# Invoice data generator\n",
    "from templates.invoicegen import create_invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2200,
     "status": "ok",
     "timestamp": 1521011601032,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "U80fgzU4JAQg",
    "outputId": "513d7fdc-73b3-44bf-d5e8-f0fadca170f4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1ac68f8c9ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Your friendly tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your friendly tokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "h8AtNKmOJAQn"
   },
   "outputs": [],
   "source": [
    "# Create 100 invoices for each template\n",
    "\n",
    "invoices = []\n",
    "targets = []\n",
    "\n",
    "# Load template 1\n",
    "with open('templates/TEMPLATE_1.txt', 'r') as content_file:\n",
    "    content = content_file.read()\n",
    "\n",
    "# Create invoices from template\n",
    "for i in range(100):\n",
    "    inv, tar = create_invoice(content)\n",
    "    invoices.append(inv)\n",
    "    targets.append(tar)\n",
    "    \n",
    "# Load template 2\n",
    "with open('templates/TEMPLATE_2.txt', 'r') as content_file:\n",
    "    content = content_file.read()\n",
    "    \n",
    "# Create invoices from template\n",
    "for i in range(100):\n",
    "    inv, tar = create_invoice(content)\n",
    "    invoices.append(inv)\n",
    "    targets.append(tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5U69d52YJAQr"
   },
   "outputs": [],
   "source": [
    "len(targets)\n",
    "r=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lEGW0NoBW-xk"
   },
   "outputs": [],
   "source": [
    "r +=1\n",
    "print(invoices[r])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xwm5ToJGJAQv"
   },
   "source": [
    "## Generate substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Lv7HCR6ZJAQv"
   },
   "outputs": [],
   "source": [
    "# Create our tokenizer\n",
    "# We will tokenize on character level!\n",
    "# We will NOT remove any characters\n",
    "tokenizer = Tokenizer(char_level=True, filters=None)  # lower = False perhaps?\n",
    "tokenizer.fit_on_texts(invoices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fardNlOkJAQz"
   },
   "outputs": [],
   "source": [
    "def gen_sub(inv,tar,pad, m = None):\n",
    "    '''\n",
    "    Generates a substring from invoice inv and target list tar \n",
    "    using the character at index m as a midpoint.\n",
    "    \n",
    "    Params:\n",
    "    inv - an invoice string\n",
    "    tar - a target list specifying the type of each item\n",
    "    pad - the amount of padding to attach before and after the focus character\n",
    "    \n",
    "    Returns:\n",
    "    sub - a string with pad characters, the focus character, pad characters\n",
    "    '''\n",
    "    # If no focus character index is set, choose at random\n",
    "    if m == None:\n",
    "        m = np.random.randint(0,len(inv))\n",
    "        \n",
    "    l = m - pad # define the lower bound of our substring\n",
    "    h = m + pad + 1 # define the upper (high) of our substring\n",
    "\n",
    "    # Sometimes, our lower bound could be below zero\n",
    "    # In this case we attach the remaining characters from the back of the string\n",
    "    if l < 0:\n",
    "        # Get the characters from the back of the file\n",
    "        s1 = inv[l:None]\n",
    "        \n",
    "        # Edge case: Sample size larger than string\n",
    "        # Our upper bound might be higher than the lenth of the text\n",
    "        # In that case we start from the front again\n",
    "        if h >= len(inv): \n",
    "            # How many characters do we need from the front\n",
    "            overlap = h - len(inv)\n",
    "            # The string is the entire invoice + some chars from the front\n",
    "            s2 = inv\n",
    "            s_over = inv[None:overlap]\n",
    "            s2 = s2 + s_over\n",
    "        else:\n",
    "            # If we don't need chars from the front \n",
    "            # we can just select to the upper bound\n",
    "            s2 = inv[None:h]\n",
    "            \n",
    "        # Create substring\n",
    "        sub = s1 + s2\n",
    "        # Ensure the substring has the right length\n",
    "        assert(len(sub) == pad*2 +1)\n",
    "        return sub, tar[m]\n",
    "    \n",
    "    # Our lower bound might be positive but our upper bound might \n",
    "    # still be above the length of the invoice\n",
    "    elif h >= len(inv):\n",
    "        # Calc how many chars we need from the front\n",
    "        overlap = h - len(inv)\n",
    "        \n",
    "        # Get string from lower bound to end\n",
    "        s1 = inv[l:None]\n",
    "        # Get string from the front of the doc\n",
    "        s2 = inv[None:overlap]\n",
    "        sub = s1 + s2\n",
    "        # Make sure our string has the correct length\n",
    "        assert(len(sub) == pad*2 +1)\n",
    "        return sub, tar[m]\n",
    "    \n",
    "    # Upper and lower bound lie within the length of the invoice\n",
    "    else: \n",
    "        sub = inv[l:h]\n",
    "        assert(len(sub) == pad*2 +1)\n",
    "        return sub, tar[m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LloL1ejTJAQ5"
   },
   "source": [
    "## Generate dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "O1rC068zJAQ5"
   },
   "outputs": [],
   "source": [
    "def gen_dataset(sample_size, n_classes, invoices, targets, tokenizer):\n",
    "    '''\n",
    "    Generate a dataset of inputs and outputs for our neural network\n",
    "    \n",
    "    Params:\n",
    "    sample_size - desired sample size\n",
    "    n_classes - number of classes\n",
    "    invoices - list of invoices to sample from\n",
    "    targets - list of corresponding targets to sample from\n",
    "    tokenizer - a keras tokenizer fit on the invoices\n",
    "    \n",
    "    The function creates balanced samples by randomly sampling untill \n",
    "    an equal amount of samples of all types is created.\n",
    "    \n",
    "    Characters are one hot encoded\n",
    "    \n",
    "    Returns:\n",
    "    x_arr: a numpy array of shape (sample_size, sequence length, number of unique characters)\n",
    "    y_arr: a numpy array of shape (sample_size,)\n",
    "    '''\n",
    "    \n",
    "    # Create a budget\n",
    "    budget = [sample_size / n_classes] * n_classes\n",
    "    \n",
    "    # Setup holding variables\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # While there is still a budget left...\n",
    "    while sum(budget) > 0:\n",
    "        # ... get a random invoice and target list\n",
    "        index = np.random.randint(0,len(invoices))\n",
    "        inv = invoices[index]\n",
    "        tar = targets[index]\n",
    "        # ... sample up to 10 items from this invoice \n",
    "        for j in range(10):\n",
    "            # Get an item\n",
    "            x, y = gen_sub(inv,tar,PADDING)\n",
    "            # if we still have a budget for this items target\n",
    "            if budget[y] > 0:\n",
    "                # Tokenize to one hot\n",
    "                xm = tokenizer.texts_to_matrix(x)\n",
    "                # Add data and target\n",
    "                X_train.append(xm)\n",
    "                y_train.append(y)\n",
    "                budget[y] -= 1\n",
    "      \n",
    "    # Create numpy arrays from all data and targets\n",
    "    x_arr = np.array(X_train)\n",
    "    y_arr = np.array(y_train)\n",
    "    return x_arr,y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3wj9GoWoc1rL"
   },
   "outputs": [],
   "source": [
    "m=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1521013240546,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "KPqhpBvWbSNX",
    "outputId": "986ca907-6df3-415e-f970-43143675759f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "('ec%\\nAan:\\n\\nORTEC Finance B.V.\\nBoompjes 40\\n', 1)\n"
     ]
    }
   ],
   "source": [
    "m += 1\n",
    "mysubstring = gen_sub(invoices[r], targets[r], PADDING, m=m)\n",
    "print(m)\n",
    "print(mysubstring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yGA5pV-3JAQ8"
   },
   "outputs": [],
   "source": [
    "# Ger data\n",
    "train_size = 12000\n",
    "val_size = 120\n",
    "\n",
    "x_tr, y_tr = gen_dataset(train_size, N_CLASSES, invoices, targets, tokenizer)\n",
    "x_val, y_val = gen_dataset(val_size, N_CLASSES, invoices, targets, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 445,
     "status": "ok",
     "timestamp": 1521014100225,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "crz627iyJAQ_",
    "outputId": "5237de92-3e93-4f77-f2a5-4278c23e4e88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 41, 85)"
      ]
     },
     "execution_count": 221,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape #a numpy array of shape (sample_size, sequence length, number of unique characters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kGzoLFbHf-kW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82CcOTIgJARD"
   },
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JJ977SYzJARD"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense,Activation, Conv1D, MaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1521013903389,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "IFzNMcqSJARG",
    "outputId": "cfdf8e76-e9dd-4833-dd00-b886699f1526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "# A simple model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32,2,input_shape=(None, 85))) # The input shape assumes there is 85 possible characters\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(SimpleRNN(10))\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 306,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1521013914249,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "UNYPtr9zJARJ",
    "outputId": "afde0c76-c2b8-44f0-dc80-b5fc954e32ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, None, 32)          5472      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 10)                430       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 5,968\n",
      "Trainable params: 5,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sparse_categorical_crossentropy is like categorical crossentropy but without converting targets to one hot\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3528,
     "status": "ok",
     "timestamp": 1521013972679,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "KL5eEhsvZ-NW",
    "outputId": "1a4477f7-ab9e-4404-da3a-072d9b2216d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 36,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1520878266967,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "SsUO4K_NaBq5",
    "outputId": "e95ca51a-c8de-430a-aa2f-1e630a478e7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "output_extras": [
      {
       "item_id": 58
      },
      {
       "item_id": 79
      },
      {
       "item_id": 80
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20135,
     "status": "ok",
     "timestamp": 1521014127430,
     "user": {
      "displayName": "rik",
      "photoUrl": "//lh6.googleusercontent.com/-ZGIi-vN4KMU/AAAAAAAAAAI/AAAAAAAAAFk/Ki-nNio6VVM/s50-c-k-no/photo.jpg",
      "userId": "113719912521762461555"
     },
     "user_tz": -60
    },
    "id": "p2JL9ObQJARL",
    "outputId": "c032498c-7357-42d2-ceb6-4f7acb4af583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 120 samples\n",
      "Epoch 1/6\n",
      "12000/12000 [==============================] - 3s 278us/step - loss: 0.8224 - acc: 0.7508 - val_loss: 0.3522 - val_acc: 0.9583\n",
      "Epoch 2/6\n",
      "12000/12000 [==============================] - 3s 262us/step - loss: 0.2576 - acc: 0.9553 - val_loss: 0.1473 - val_acc: 0.9750\n",
      "Epoch 3/6\n",
      "12000/12000 [==============================] - 3s 263us/step - loss: 0.1278 - acc: 0.9794 - val_loss: 0.1010 - val_acc: 0.9833\n",
      "Epoch 4/6\n",
      "12000/12000 [==============================] - 3s 263us/step - loss: 0.0822 - acc: 0.9870 - val_loss: 0.0606 - val_acc: 0.9833\n",
      "Epoch 5/6\n",
      " 4928/12000 [===========>..................] - ETA: 1s - loss: 0.0582 - acc: 0.991512000/12000 [==============================] - 3s 274us/step - loss: 0.0531 - acc: 0.9918 - val_loss: 0.0460 - val_acc: 0.9833\n",
      "Epoch 6/6\n",
      "12000/12000 [==============================] - 3s 274us/step - loss: 0.0383 - acc: 0.9949 - val_loss: 0.0230 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb513d6160>"
      ]
     },
     "execution_count": 222,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_tr,y_tr,batch_size=32,epochs=6,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64vCXL2TJARO"
   },
   "source": [
    "## Generate demo invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VVq9JpSCJARO"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "To make predictions from our model, we need to create \n",
    "sequences around every character from the invoice.\n",
    "\n",
    "We the making predictions for every charater based on their invoice\n",
    "'''\n",
    "\n",
    "# Choose a random invoice:\n",
    "index = np.random.randint(0,len(invoices))\n",
    "inv = invoices[index]\n",
    "tar = targets[index]\n",
    "\n",
    "\n",
    "chars = [] # Holds the individual characters\n",
    "data = [] # Holds the sequences around the characters\n",
    "y_true = [] # Holds the true targets for each character\n",
    "\n",
    "# Loop over characters indices\n",
    "for i in range(len(inv) -1):\n",
    "    # Create sequence around this character\n",
    "    x,y = gen_sub(inv,tar,PADDING,m=i)\n",
    "    # Tokenize the sequence to one hot\n",
    "    xm = tokenizer.texts_to_matrix(x)\n",
    "    # Get the character itself\n",
    "    c = inv[i]\n",
    "    \n",
    "    chars.append(c)\n",
    "    data.append(xm)\n",
    "    y_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AkoIPKFbJARS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c6dsi09WJARV"
   },
   "outputs": [],
   "source": [
    "# For demo purposes we can look what our invoice looks like\n",
    "df = pd.DataFrame({'Char':chars,'Target':y_true})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "agX4dRj0JARZ"
   },
   "outputs": [],
   "source": [
    "# Show all characters belonging to the amount\n",
    "df[df.Target == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "J0bWvclmJARg"
   },
   "outputs": [],
   "source": [
    "# Create test data for predictions with neural net\n",
    "x_test = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mH6fGzCkJARi"
   },
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KdrkkkYJARm"
   },
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "81HmeHLdJARn"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CZGiAph5JARp"
   },
   "outputs": [],
   "source": [
    "# Get the maximum likely class\n",
    "y_pred = y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "e-4IlZFkJARs"
   },
   "outputs": [],
   "source": [
    "# Show how our model predictions look like\n",
    "df['Predicted'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "P06em8DgJARt"
   },
   "outputs": [],
   "source": [
    "# Show all chars that are predicted to belong to the amount\n",
    "df[df.Predicted == 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zRYMUUrTJARy"
   },
   "source": [
    "## Obtain system outputs from predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rZHf701mJARz"
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "# Create groups by the predicted output\n",
    "# The this code will return a tuple with the format\n",
    "# (category, length, starting index)\n",
    "\n",
    "# TODO: This code is ugly and very hard to understand\n",
    "# But it works\n",
    "\n",
    "# Group by predicted category\n",
    "g = groupby(enumerate(y_pred), lambda x:x[1])\n",
    "\n",
    "# Create list of groups\n",
    "l = [(x[0], list(x[1])) for x in g]\n",
    "\n",
    "# Create list with tuples of groups\n",
    "groups = [(x[0], len(x[1]), x[1][0][0]) for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "M40M3Y8eJAR2"
   },
   "outputs": [],
   "source": [
    "# Show grouping\n",
    "groups[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_J6W-RV2JAR4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We only want to consider sequences of predictions of the same type \n",
    "that have a minimum length. This way we remove the noise\n",
    "But we also might remove some good predictions\n",
    "\n",
    "The min length is set to 5 here, certainly a value to experiment with\n",
    "'''\n",
    "candidates = []\n",
    "# Loop over all groups\n",
    "for group in groups:\n",
    "    \n",
    "    # Unpack group\n",
    "    category, length, index = group\n",
    "    \n",
    "    # Ignore the ignore category and only consider category sequences longer than 5\n",
    "    if category != 0 and length > 5:\n",
    "        # Create text\n",
    "        candidate_text = ''.join(chars[index:index+length])\n",
    "        # Remove line breaks, this is just one way to prettify outputs!\n",
    "        candidate_text = candidate_text.replace('\\n','')\n",
    "        candidates.append((candidate_text,category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q92fYU5HJAR7"
   },
   "outputs": [],
   "source": [
    "# Show predictions\n",
    "\n",
    "'''\n",
    "Ignore:           0\n",
    "Sender Name:      1 \n",
    "Sender KVK:       2 \n",
    "Sender IBAN:      3 \n",
    "Invoice Reference:4\n",
    "Total:            5\n",
    "'''\n",
    "\n",
    "sorted(candidates, key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pVtUhpFFJAR-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ru8U0J-BJASA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Jannes Baseline Ortec.ipynb",
   "provenance": [
    {
     "file_id": "1wjtiXpxRkuN5V57GiK_RSPxy84cFbERO",
     "timestamp": 1520877467293
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
